{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01375c32",
   "metadata": {},
   "source": [
    "# Assignment 4: Face Detection and Recognition\n",
    "\n",
    "## DTSC-680: Applied Machine Learning\n",
    "\n",
    "## Name: Angelica LOZANO GOMEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d53fe0",
   "metadata": {},
   "source": [
    "The `data` directory contains three folders 30 face images of three players from the 2024 Philadelphia Phillies: Alec Bohm, Bryson Stott, and Brandon Marsh. The original images were downloaded from Google Images and the face images were extraced using the `extract_faces` function from the textbook. In addition, the `Samples` directory contains three images of a combination of those players.\n",
    "\n",
    "Your task is to create a system that can correctly detect and identify Bohm, Stott, and Marsh in those three sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89221e-4ba7-44f8-980e-1780373fa435",
   "metadata": {},
   "source": [
    "### Install Tensorflow 2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9ad8f1-cfb8-4230-92f1-6d7840f0b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 2.9.2 is already installed.\n"
     ]
    }
   ],
   "source": [
    "# CODE PROVIDED\n",
    "import subprocess\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "def check_tensorflow():\n",
    "    tf_desired_version = \"2.9.2\"\n",
    "\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        tf_installed_version = tf.__version__\n",
    "    except ImportError:\n",
    "        tf_installed_version = None\n",
    "\n",
    "    #Check for the right version\n",
    "    if tf_installed_version != tf_desired_version:\n",
    "        print(f\"Current TensorFlow version: {tf_installed_version}. Installing version {tf_desired_version}...\")\n",
    "        \n",
    "        # Uninstall the current TensorFlow version\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'uninstall', '-y', 'tensorflow'])\n",
    "        \n",
    "        # Install the desired TensorFlow version\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', f'tensorflow=={tf_desired_version}'])\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        print(f\"TensorFlow version {tf_desired_version} installed successfully. Please restart your kernel to apply the changes.\")\n",
    "    else:\n",
    "        print(f\"TensorFlow version {tf_desired_version} is already installed.\")    \n",
    "\n",
    "check_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ab33b6-733f-4219-8c9b-335b0d7cedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE 1\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input as vgg_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2164d43-b8a4-442d-8e6f-07b7c62b1032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bohm: 10 images\n",
      "Stott: 10 images\n",
      "Marsh: 10 images\n",
      "Total training images: 30\n"
     ]
    }
   ],
   "source": [
    "# STUDENT CODE 2\n",
    "label_map = {\n",
    "    'Bohm': 0,\n",
    "    'Stott': 1,\n",
    "    'Marsh': 2\n",
    "}\n",
    "folders_to_use = list(label_map.keys())\n",
    "train_path = 'data'\n",
    "\n",
    "total_images = 0\n",
    "for folder in folders_to_use:\n",
    "    folder_path = os.path.join(train_path, folder)\n",
    "    count = len([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"{folder}: {count} images\")\n",
    "    total_images += count\n",
    "\n",
    "print(\"Total training images:\", total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7830dd-c0a1-49f1-a524-4b730e924253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for Bohm: 0\n",
      "Label for Stott: 1\n",
      "Label for Marsh: 2\n"
     ]
    }
   ],
   "source": [
    "# STUDENT CODE 3\n",
    "for folder in folders_to_use:\n",
    "    print(f\"Label for {folder}: {label_map[folder]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9528c607-9937-491a-9b94-3bc58c163e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE 4\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from keras_vggface.utils import preprocess_input as vgg_preprocess\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for folder in folders_to_use:\n",
    "    label = label_map[folder]\n",
    "    folder_path = os.path.join(train_path, folder)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            img = load_img(full_path, target_size=(224, 224))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = vgg_preprocess(np.expand_dims(img_array, axis=0))\n",
    "            X.append(img_array[0])\n",
    "            y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8247c608-a2d9-44f5-b2d5-742dd3677e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT CODE 5\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089d3ffa-f9a3-4514-9178-23cbf63b4cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 08:25:33.765122: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-24 08:25:33.765221: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# STUDENT CODE 6\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "base_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30373cfe-aba6-401f-b81c-b7def16271a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 08:25:34.683510: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2025-04-24 08:25:35.715426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-24 08:25:37.279067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 3s - loss: 4.8418 - accuracy: 0.4583 - val_loss: 2.8473e-04 - val_accuracy: 1.0000 - 3s/epoch - 526ms/step\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 1.0750 - accuracy: 0.7083 - val_loss: 2.2668e-05 - val_accuracy: 1.0000 - 281ms/epoch - 47ms/step\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 2.4747 - accuracy: 0.7917 - val_loss: 1.1054 - val_accuracy: 0.6667 - 254ms/epoch - 42ms/step\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.2233 - accuracy: 0.9167 - val_loss: 0.0542 - val_accuracy: 1.0000 - 252ms/epoch - 42ms/step\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.0862 - accuracy: 0.9583 - val_loss: 3.9736e-08 - val_accuracy: 1.0000 - 255ms/epoch - 42ms/step\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.3836 - accuracy: 0.9167 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - 252ms/epoch - 42ms/step\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.6660 - accuracy: 0.9167 - val_loss: 1.1921e-07 - val_accuracy: 1.0000 - 246ms/epoch - 41ms/step\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.6361 - accuracy: 0.7917 - val_loss: 0.4681 - val_accuracy: 0.8333 - 245ms/epoch - 41ms/step\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.0871 - accuracy: 0.9583 - val_loss: 1.5399 - val_accuracy: 0.6667 - 246ms/epoch - 41ms/step\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.2436 - accuracy: 0.9167 - val_loss: 0.5736 - val_accuracy: 0.8333 - 246ms/epoch - 41ms/step\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000 - 329ms/epoch - 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# STUDENT CODE 7\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define helper used by make_pred\n",
    "def get_face(np_image, face, required_size=(224, 224)):\n",
    "    x1, y1, width, height = face['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face_crop = np_image[y1:y2, x1:x2]\n",
    "    image_resized = cv2.resize(face_crop, required_size)\n",
    "    return image_resized\n",
    "\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    augmenter.flow(X_train, y_train, batch_size=4),\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,  # Increased from 50 to 100\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691da19f-19cc-48f4-abaa-9496b7baa3d5",
   "metadata": {},
   "source": [
    "## Codegrade Validation\n",
    "\n",
    "### Execute the cells below to generate the file required for submission to Codegrade. DO NOT CHANGE THE CODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dfd7ede-edb6-411d-8b4a-497507ae8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PROVIDED\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from PIL import Image, ImageOps\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "def make_pred(path, model, names, face_threshold=0.9, prediction_threshold=0.9, show_outline=True, size=(12, 8)):\n",
    "    # Load the image and orient it correctly\n",
    "    pil_image = Image.open(path)\n",
    "    exif = pil_image.getexif()\n",
    "    \n",
    "    for k in exif.keys():\n",
    "        if k != 0x0112:\n",
    "            exif[k] = None\n",
    "            del exif[k]\n",
    "            \n",
    "    pil_image.info[\"exif\"] = exif.tobytes()\n",
    "    pil_image = ImageOps.exif_transpose(pil_image)\n",
    "    np_image = np.array(pil_image)\n",
    "\n",
    "    detector = MTCNN()\n",
    "    faces = detector.detect_faces(np_image)\n",
    "    faces = [face for face in faces if face['confidence'] > face_threshold]\n",
    "\n",
    "    for face in faces:\n",
    "        x, y, w, h = face['box']\n",
    "\n",
    "        # Use the model to identify the face\n",
    "        face_image = get_face(np_image, face)\n",
    "        face_image = image.array_to_img(face_image)\n",
    "        face_image = preprocess_input(np.array(face_image))\n",
    "        predictions = model.predict(np.expand_dims(face_image, axis=0))\n",
    "        confidence = np.max(predictions)\n",
    "\n",
    "        if (confidence > prediction_threshold):\n",
    "            return predictions\n",
    "            \n",
    "\n",
    "        return None\n",
    "        \n",
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "def get_all_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    images_names = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_path = os.path.join(directory, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            images_names += [img for img in os.listdir(label_path)]\n",
    "            images += [os.path.join(label_path, img) for img in os.listdir(label_path)]\n",
    "            labels += [int(label)] * len(os.listdir(label_path))\n",
    "    \n",
    "    # Embaralhar as imagens e labels\n",
    "    combined = list(zip(images_names, images, labels))\n",
    "    random.shuffle(combined)\n",
    "    images_names, images, labels = zip(*combined)\n",
    "    \n",
    "    #return images_names, images, labels\n",
    "    return zip(*combined)\n",
    "\n",
    "def predict_and_validate(model, image_names, image_paths, true_labels, class_labels):\n",
    "    predictions = []\n",
    "    for img_path in image_paths:\n",
    "        predictions.append(make_pred(img_path, model, class_labels, prediction_threshold=0.8))\n",
    "    \n",
    "    results = [true == pred for true, pred in zip(true_labels, predictions)]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Player': image_names,\n",
    "        'Prediction Array': predictions\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc8debe-7e9c-4738-8a69-7914ae0a2d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Prediction Array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bryson_09.png</td>\n",
       "      <td>[[2.367299e-11, 1.0, 1.1893617e-21]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alec_07.jpg</td>\n",
       "      <td>[[1.0, 1.0928834e-11, 4.5577733e-15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alec_02.jpg</td>\n",
       "      <td>[[1.0, 5.20231e-12, 2.5790213e-16]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alec_06.jpg</td>\n",
       "      <td>[[1.0, 2.2493726e-12, 2.7165634e-13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brandon_08.png</td>\n",
       "      <td>[[1.8212669e-06, 5.541312e-07, 0.9999976]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alec_01.jpg</td>\n",
       "      <td>[[1.0, 8.1304775e-14, 2.623304e-13]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bryson_04.png</td>\n",
       "      <td>[[1.4542277e-12, 1.0, 1.5317565e-21]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alec_05.jpg</td>\n",
       "      <td>[[0.9999845, 1.5488878e-05, 9.418053e-10]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brandon_04.png</td>\n",
       "      <td>[[4.6691318e-07, 2.124318e-05, 0.9999783]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bryson_06.png</td>\n",
       "      <td>[[4.1001262e-16, 1.0, 3.18551e-20]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brandon_03.png</td>\n",
       "      <td>[[2.2683703e-14, 7.607712e-09, 1.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alec_04.jpg</td>\n",
       "      <td>[[4.560191e-06, 0.99999547, 6.9512642e-12]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brandon_07.png</td>\n",
       "      <td>[[1.4318627e-18, 4.6323376e-07, 0.9999995]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player                             Prediction Array\n",
       "0    Bryson_09.png         [[2.367299e-11, 1.0, 1.1893617e-21]]\n",
       "1      alec_07.jpg        [[1.0, 1.0928834e-11, 4.5577733e-15]]\n",
       "2      alec_02.jpg          [[1.0, 5.20231e-12, 2.5790213e-16]]\n",
       "3      alec_06.jpg        [[1.0, 2.2493726e-12, 2.7165634e-13]]\n",
       "4   Brandon_08.png   [[1.8212669e-06, 5.541312e-07, 0.9999976]]\n",
       "5      alec_01.jpg         [[1.0, 8.1304775e-14, 2.623304e-13]]\n",
       "6    Bryson_04.png        [[1.4542277e-12, 1.0, 1.5317565e-21]]\n",
       "7      alec_05.jpg   [[0.9999845, 1.5488878e-05, 9.418053e-10]]\n",
       "8   Brandon_04.png   [[4.6691318e-07, 2.124318e-05, 0.9999783]]\n",
       "9    Bryson_06.png          [[4.1001262e-16, 1.0, 3.18551e-20]]\n",
       "10  Brandon_03.png         [[2.2683703e-14, 7.607712e-09, 1.0]]\n",
       "11     alec_04.jpg  [[4.560191e-06, 0.99999547, 6.9512642e-12]]\n",
       "12  Brandon_07.png  [[1.4318627e-18, 4.6323376e-07, 0.9999995]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE PROVIDED\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model_to_evaluate = model  #MAKE SURE TO USE YOUR MODEL\n",
    "\n",
    "class_labels = {0: 'Alec Bohm', 1: 'Bryson Stott', 2: 'Brandon Marsh'} \n",
    "image_names, image_paths, true_labels = get_all_images_from_directory('data/codegrade_test/')\n",
    "prediction_df = predict_and_validate(model_to_evaluate, image_names, image_paths, true_labels, class_labels)\n",
    "clear_output()\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427b877-bc6b-4aa9-83dc-4bd38c9f2a24",
   "metadata": {},
   "source": [
    "### Export Prediction Array for Codegrade evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4e8d4fc-69a2-48c0-922d-119c75f663f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE PROVIDED\n",
    "import pandas as pd\n",
    "\n",
    "#export your classification model\n",
    "prediction_df.to_pickle('prediction_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f6144-22ee-4d05-9145-dcf4d63598dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
